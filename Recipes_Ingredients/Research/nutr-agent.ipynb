{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc83d47",
   "metadata": {},
   "source": [
    "## Multimodal‚ÄëNutrition Agent ‚Äî https://haystack.deepset.ai/blog/multimodal-nutrition-agent?utm_source=substack&utm_medium=email\n",
    "### 0¬†¬†Current Status\n",
    "- **Vision still pending - and will not be implemented**  \n",
    "  All tests so far were **text‚Äëonly**: we retrieved the label *captions* and reasoned with small CPU models (TinyLlama, Phi‚Äë2).  \n",
    "  The image side (`MultiModalPromptBuilder` + vision LLM such as **Phi‚Äë3.5‚ÄØVision**) will be plugged in once GPU inference is enabled.\n",
    "\n",
    "### 1¬†¬†Motivation\n",
    "- **Problem**  \n",
    "  Nutrition questions (e.g. *‚ÄúWhich snack has more protein?‚Äù*) require reasoning over both the **image** (nutrition‚Äêlabel photo) and **text** (user query).  \n",
    "- **Goal**  \n",
    "  Build a lightweight *Multimodal Nutrition Agent* that can  \n",
    "  1. **Store** nutrition‚Äëlabel images with short captions,  \n",
    "  2. **Retrieve** the relevant label for a query, and  \n",
    "  3. **Reason** over that image/text with a vision‚Äëcapable LLM, replying in plain English.  \n",
    "- **Constraints**  \n",
    "  Runs locally, works on CPU first, later pluggable into your Postgres‚ÄØ+‚ÄØpgvector recipe stack.\n",
    "\n",
    "---\n",
    "\n",
    "### 2¬†¬†Inspiration¬†‚Äì deepset Haystack Blog\n",
    "| Stage | What the article shows | Why it matters to our build |\n",
    "|-------|------------------------|-----------------------------|\n",
    "| **Data prep** | nutrition‚Äëlabel images in JSON ‚Üí `Document(content, meta)` | Same structure; we can swap in any JPG/PNG later. |\n",
    "| **Indexing** | `SentenceTransformersDocumentEmbedder` ‚Üí `InMemoryDocumentStore` | Identical flow (we'll point to pgvector later). |\n",
    "| **Retrieval pipeline** | User query ‚Üí text embedding ‚Üí top‚Äë1 label ‚Üí `MultiModalPromptBuilder` injects Base‚Äë64 image into prompt | Ready‚Äëmade component for mixing image + text. |\n",
    "| **Tool wrapper** | Expose retrieval as `DocWithImageHaystackQueryTool` | Lets an **agent** call the pipeline only when needed. |\n",
    "| **Generator** | `Phi35VisionHFGenerator` (4‚ÄØB) | We started with TinyLlama (CPU) and can upgrade to Phi‚Äë3.5‚ÄëVision once GPU is enabled. |\n",
    "| **Agent prompt** | ReAct template (Thought ‚Üí Action ‚Üí Observation ‚Üí Final¬†Answer) | Matches the tool‚Äëcalling style you already use. |\n",
    "| **Examples** | Single‚Äëhop (‚ÄúHow much fat‚Ä¶?‚Äù) and multi‚Äëhop comparison | Confirms the agent can chain tool outputs and reason. |\n",
    "\n",
    "---\n",
    "\n",
    "### 3¬†¬†Implementation References\n",
    "| Area | Minimal component / reference |\n",
    "|------|------------------------------|\n",
    "| **Multimodal prompting** | *Li‚ÄØet‚ÄØal.,¬†2023* ‚ÄúAlign before fuse‚Äù (vision‚Äëlanguage instruction tuning) |\n",
    "| **Vision LLMs (open)** | Phi‚Äë3.5‚ÄØVision ‚Ä¢ LLaVA‚Äë1.5 ‚Ä¢ BLIP‚Äë2 |\n",
    "| **Agent framework** | [fastRAG¬†3.x](https://github.com/IntelLabs/fastRAG) ‚Äì ReAct agent & tools |\n",
    "| **Vector search** | `pgvector`‚ÄØ+‚ÄØPostgres¬†16; fallback: `InMemoryDocumentStore` |\n",
    "| **Sentence embeddings** | `sentence-transformers/all-MiniLM-L6-v2` (384‚Äëd) |\n",
    "| **Dataset sources** | Blog JSON sample; USDA Branded Foods (text, can add images) |\n",
    "| **Prompt‚Äëengineering** | ReAct (*Yao‚ÄØet‚ÄØal.,¬†2023*) ‚Äì reasoning + acting loop |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c31c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\turgu\\anaconda3\\envs\\mm-nutrition\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib, os, colorama\n",
    "colorama.init(strip=True)\n",
    "from haystack import Pipeline, Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.embedders import (\n",
    "    SentenceTransformersDocumentEmbedder,\n",
    "    SentenceTransformersTextEmbedder,\n",
    ")\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.generators import HuggingFaceLocalGenerator\n",
    "\n",
    "from fastrag.prompt_builders.multi_modal_prompt_builder import MultiModalPromptBuilder\n",
    "from fastrag.agents.tools.tools import DocWithImageHaystackQueryTool\n",
    "from fastrag.agents.base import Agent, ToolsManager\n",
    "from fastrag.agents.create_agent import ConversationMemory\n",
    "\n",
    "from transformers import AutoTokenizer, TextIteratorStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c896044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_path = pathlib.Path(\"nutrition_demo.json\")\n",
    "entries = json.loads(demo_path.read_text(encoding=\"utf-8\"))\n",
    "docs = [Document(content=e[\"content\"], meta=e) for e in entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ccccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 39.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 6}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = InMemoryDocumentStore()\n",
    "index = Pipeline()\n",
    "index.add_component(\n",
    "    \"embed\",\n",
    "    SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    ")\n",
    "index.add_component(\"writer\", DocumentWriter(document_store=store))\n",
    "index.connect(\"embed.documents\", \"writer.documents\")\n",
    "index.run({\"embed\": {\"documents\": docs}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feecc5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptBuilder has 1 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000023281BD4B90>\n",
       "üöÖ Components\n",
       "  - q_emb: SentenceTransformersTextEmbedder\n",
       "  - ret: InMemoryEmbeddingRetriever\n",
       "  - prompt: MultiModalPromptBuilder\n",
       "üõ§Ô∏è Connections\n",
       "  - q_emb.embedding -> ret.query_embedding (List[float])\n",
       "  - ret.documents -> prompt.documents (List[Document])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Label: {{ documents[0].content }}\"\n",
    "retrieval = Pipeline()\n",
    "retrieval.add_component(\"q_emb\", SentenceTransformersTextEmbedder(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "retrieval.add_component(\"ret\", InMemoryEmbeddingRetriever(\n",
    "    document_store=store, top_k=1))\n",
    "retrieval.add_component(\"prompt\", MultiModalPromptBuilder(template=template))\n",
    "retrieval.connect(\"q_emb.embedding\", \"ret.query_embedding\")\n",
    "retrieval.connect(\"ret\", \"prompt.documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db81138",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_tool = DocWithImageHaystackQueryTool(\n",
    "    name=\"nutrition_tool\",\n",
    "    description=\"Retrieve the most relevant nutrition label text\",\n",
    "    pipeline_or_yaml_file=retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb28f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\turgu\\anaconda3\\envs\\mm-nutrition\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\turgu\\.cache\\huggingface\\hub\\models--TinyLlama--TinyLlama-1.1B-Chat-v1.0. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "generator = HuggingFaceLocalGenerator(\n",
    "    model=model_name,\n",
    "    task=\"text-generation\",\n",
    "    generation_kwargs={\"max_new_tokens\": 160, \"temperature\": 0.2, \"num_beams\": 1},\n",
    ")\n",
    "generator.warm_up() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6dab37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = generator.pipeline.tokenizer          \n",
    "dummy_streamer = TextIteratorStreamer(tokenizer, skip_prompt=True)\n",
    "generator.generation_kwargs[\"streamer\"] = dummy_streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df01d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent Agent started with {'query': 'Which has more protein, the protein bar or the yogurt?', 'params': None}\n",
      "The protein bar has more protein than the yogurt. A 100g serving of protein bar contains 12g of protein, while a 100g serving of plain Greek yogurt contains 8g of protein.\n",
      "The protein bar has more protein than the yogurt. A 100g serving of protein bar contains 12g of protein, while a 100g serving of plain Greek yogurt contains 8g of protein.\n",
      "\n",
      "Final answer\n",
      " ‚ü®missing‚ü©\n"
     ]
    }
   ],
   "source": [
    "one_shot = \"\"\"\n",
    "### EXAMPLE\n",
    "User: How much protein is in the protein bar?\n",
    "Thought: I need to look up the label.\n",
    "Action: nutrition_tool({{{{\"text_query\": \"protein bar protein grams\"}}}})\n",
    "Observation: Label: Protein bar: 12 g protein, 8 g fat, 23 g carbs, 200 kcal\n",
    "Thought: I have the information.\n",
    "Final Answer: The protein bar contains 12‚ÄØg of protein.\n",
    "### END EXAMPLE\n",
    "\"\"\"\n",
    "\n",
    "agent_prompt = f\"\"\"You are a helpful nutrition assistant.\n",
    "You may call tools to look up nutrition labels.\n",
    "\n",
    "TOOLS:\n",
    "{{tool_names_with_descriptions}}\n",
    "\n",
    "{one_shot}\n",
    "\n",
    "RESPONSE FORMAT\n",
    "Thought:\n",
    "Action: nutrition_tool({{{{\"text_query\": \"...\"}}}})\n",
    "Observation:\n",
    "... (repeat) ...\n",
    "Final Answer: the answer to the user's question\n",
    "\n",
    "Begin!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Build the agent (re‚Äëuse the nutrition_tool we already defined)\n",
    "agent = Agent(\n",
    "    generator,\n",
    "    prompt_template={\n",
    "        \"system\": [{\"role\": \"system\", \"content\": agent_prompt}],\n",
    "        \"chat\":   [{\"role\": \"user\",   \"content\": \"{query}\"}],\n",
    "    },\n",
    "    tools_manager=ToolsManager([nutrition_tool]),\n",
    "    memory=ConversationMemory(generator=generator),\n",
    "    final_answer_pattern=r\"Final Answer:\\s*(.*)\",\n",
    "    streaming=False  \n",
    ")\n",
    "\n",
    "# Run a test question\n",
    "result = agent.run(\"Which has more protein, the protein bar or the yogurt?\")\n",
    "print(result[\"transcript\"])\n",
    "print(\"\\nFinal answer\\n\", result.get(\"final_answer\", \"‚ü®missing‚ü©\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm-nutrition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
